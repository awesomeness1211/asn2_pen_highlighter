{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5ed141-cee7-4bc2-a3c9-18334a9f893d",
   "metadata": {},
   "source": [
    "# ASN2 - Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c701e-d4d0-42fc-951d-4fcb44e8c355",
   "metadata": {},
   "source": [
    "In this assignment, I will go through how to detect objects using YOLOv8 to do so. This involves the classification of images of pens and highlighters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0a36782-426b-476c-b32b-58f38f3ce7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "wget https://github.com/awesomeness1211/asn2_pen_highlighter/blob/main/pen_highlighter_annotated_dataset.zip\n",
    "mkdir -p datasets\n",
    "unzip pen_highlighter_annotated_dataset.zip -d datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316047a8-efcb-49ea-851f-53129bda6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6cc1ef-3370-4677-9fdb-72c03984656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "settings.update({\"wandb\": True,\n",
    "                 \"tensorboard\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632452cb-18c0-476e-9720-5da383275916",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")  # Load a pre-trained YOLO model\n",
    "result = model.train(data=\"datasets/data.yaml\",\n",
    "                     epochs=30,\n",
    "                     save_period=1,\n",
    "                     batch=16,\n",
    "                     device=0,\n",
    "                     project='penhighlighter',\n",
    "                     plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e9e52-a8b7-45e2-aa50-525f9e654ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"penhighlighter/train/weights/best.pt\")\n",
    "validation_results = model.val(data=\"datasets/data.yaml\", device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45c5d6-063c-41d3-8eee-b4c3cde7ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics.utils.benchmarks import benchmark\n",
    "\n",
    "# # Benchmark on GPU (device=0 means the 1st GPU device)\n",
    "# benchmark(model=\"balloon/train/weights/best.pt\", data=\"datasets/data.yaml\", imgsz=640, half=False, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787225ff-743f-4257-9432-a9744759d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"penhighlighter/train/weights/best.pt\")\n",
    "exported_path = model.export(format=\"openvino\", int8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07fa47-2ee4-4499-9a4b-2e9ccc01a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "source = 'https://github.com/nyp-sit/it3103-2025S1/raw/refs/heads/main/week5_object_detection/samples/sample_pen_highlighter.jpeg'\n",
    "model = YOLO(\"balloon/train/weights/best_int8_openvino_model\", task='detect')\n",
    "result = model(source, conf=0.5, iou=0.6)\n",
    "\n",
    "# Visualize the results\n",
    "for i, r in enumerate(result):\n",
    "    print(r)\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "    # Show results to screen (in supported environments)\n",
    "    r.show()\n",
    "\n",
    "    # Save results to disk\n",
    "    r.save(filename=f\"results{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c6469-cad9-4d60-a5f3-1ce43a056088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import locale\n",
    "# locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452d8a2-e5d2-4c7b-adc9-fc08ba1d1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv ./balloon/train/weights/best_int8_openvino_model/ .\n",
    "zip -r best_int8_openvino_model.zip best_int8_openvino_model\n",
    "!wget https://github.com/nyp-sit/it3103-2025S1/raw/refs/heads/main/week5_object_detection/samples/balloon.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3d7c2-a26c-47fd-956b-e935d0bee224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow  # ✅ Use this for Colab\n",
    "import time\n",
    "\n",
    "# Load the YOLO model (OpenVINO int8)\n",
    "model = YOLO(\"best_int8_openvino_model\", task=\"detect\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"pen_highlighter.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO inference on the frame using CPU (OpenVINO)\n",
    "        results = model(frame, device=\"cpu\")\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # ✅ Display the annotated frame using Colab-compatible method\n",
    "        cv2_imshow(annotated_frame)\n",
    "\n",
    "        # Wait briefly to simulate real-time video playback (adjust as needed)\n",
    "        time.sleep(0.1)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246efa3c-d7a8-4e36-83bb-45b9264a675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def write_video(video_in_filepath, video_out_filepath, model):\n",
    "    # Open the video file\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_in_filepath)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = video_reader.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    video_writer = cv2.VideoWriter(video_out_filepath,\n",
    "                            cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                            fps,\n",
    "                            (frame_w, frame_h))\n",
    "\n",
    "    # Loop through the video frames\n",
    "    for i in tqdm(range(nb_frames)):\n",
    "        # Read a frame from the video\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLO inference on the frame on GPU Device 0\n",
    "            results = model(frame, device=0)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Write the annotated frame\n",
    "            video_writer.write(annotated_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad2ae2-5136-470d-b7c3-1b669304a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "video_in_file = \"pen_highlighter.mp4\"\n",
    "basename = Path(video_in_file).stem\n",
    "video_out_file = os.path.join(basename + '_detected' + '.mp4')\n",
    "model = YOLO(\"best_int8_openvino_model\", task=\"detect\")\n",
    "write_video(video_in_file, video_out_file, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
