{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5ed141-cee7-4bc2-a3c9-18334a9f893d",
   "metadata": {},
   "source": [
    "# ASN2 - Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2c701e-d4d0-42fc-951d-4fcb44e8c355",
   "metadata": {},
   "source": [
    "In this assignment, I will go through how to detect objects using YOLOv8 to do so. This involves the classification of images of pens and highlighters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0a36782-426b-476c-b32b-58f38f3ce7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%bash\n",
    "wget https://github.com/awesomeness1211/asn2_pen_highlighter/blob/main/pen_highlighter_annotated_dataset.zip\n",
    "mkdir -p datasets\n",
    "unzip pen_highlighter_annotated_dataset.zip -d datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "316047a8-efcb-49ea-851f-53129bda6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c6cc1ef-3370-4677-9fdb-72c03984656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "settings.update({\"wandb\": True,\n",
    "                 \"tensorboard\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "632452cb-18c0-476e-9720-5da383275916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.5M/21.5M [00:01<00:00, 16.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.164 ðŸš€ Python-3.12.7 torch-2.7.1 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: -1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolov8s.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load a pre-trained YOLO model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m                      epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m      6\u001b[0m                      save_period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m                      batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      8\u001b[0m                      device\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m                      project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpenhighlighter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                      plots\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:793\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    791\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m (trainer \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ultralytics/engine/trainer.py:121\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(cfg, overrides)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_resume(overrides)\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m select_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Update \"-1\" devices so post-training val does not repeat search\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ultralytics/utils/torch_utils.py:202\u001b[0m, in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    195\u001b[0m         LOGGER\u001b[38;5;241m.\u001b[39minfo(s)\n\u001b[1;32m    196\u001b[0m         install \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA devices are seen by torch.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    200\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m         )\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requested.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or pass valid CUDA device(s) if available,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m i.e. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice=0,1,2,3\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for Multi-GPU.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.is_available(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtorch.cuda.device_count(): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mos.environ[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvisible\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minstall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cpu \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mps \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():  \u001b[38;5;66;03m# prefer GPU if available\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     devices \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# i.e. \"0,1\" -> [\"0\", \"1\"]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: -1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8s.pt\")  # Load a pre-trained YOLO model\n",
    "result = model.train(data=\"datasets/data.yaml\",\n",
    "                     epochs=30,\n",
    "                     save_period=1,\n",
    "                     batch=16,\n",
    "                     device=0,\n",
    "                     project='penhighlighter',\n",
    "                     plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e9e52-a8b7-45e2-aa50-525f9e654ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"penhighlighter/train/weights/best.pt\")\n",
    "validation_results = model.val(data=\"datasets/data.yaml\", device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d45c5d6-063c-41d3-8eee-b4c3cde7ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics.utils.benchmarks import benchmark\n",
    "\n",
    "# # Benchmark on GPU (device=0 means the 1st GPU device)\n",
    "# benchmark(model=\"balloon/train/weights/best.pt\", data=\"datasets/data.yaml\", imgsz=640, half=False, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787225ff-743f-4257-9432-a9744759d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"penhighlighter/train/weights/best.pt\")\n",
    "exported_path = model.export(format=\"openvino\", int8=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07fa47-2ee4-4499-9a4b-2e9ccc01a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "source = 'https://github.com/awesomeness1211/asn2_pen_highlighter/blob/main/test_image.png'\n",
    "model = YOLO(\"balloon/train/weights/best_int8_openvino_model\", task='detect')\n",
    "result = model(source, conf=0.5, iou=0.6)\n",
    "\n",
    "# Visualize the results\n",
    "for i, r in enumerate(result):\n",
    "    print(r)\n",
    "    # Plot results image\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "    # Show results to screen (in supported environments)\n",
    "    r.show()\n",
    "\n",
    "    # Save results to disk\n",
    "    r.save(filename=f\"results{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c6469-cad9-4d60-a5f3-1ce43a056088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import locale\n",
    "# locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452d8a2-e5d2-4c7b-adc9-fc08ba1d1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mv ./balloon/train/weights/best_int8_openvino_model/ .\n",
    "zip -r best_int8_openvino_model.zip best_int8_openvino_model\n",
    "!wget https://github.com/nyp-sit/it3103-2025S1/raw/refs/heads/main/week5_object_detection/samples/balloon.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3d7c2-a26c-47fd-956b-e935d0bee224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow  # âœ… Use this for Colab\n",
    "import time\n",
    "\n",
    "# Load the YOLO model (OpenVINO int8)\n",
    "model = YOLO(\"best_int8_openvino_model\", task=\"detect\")\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"pen_highlighter.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLO inference on the frame using CPU (OpenVINO)\n",
    "        results = model(frame, device=\"cpu\")\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # âœ… Display the annotated frame using Colab-compatible method\n",
    "        cv2_imshow(annotated_frame)\n",
    "\n",
    "        # Wait briefly to simulate real-time video playback (adjust as needed)\n",
    "        time.sleep(0.1)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246efa3c-d7a8-4e36-83bb-45b9264a675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "def write_video(video_in_filepath, video_out_filepath, model):\n",
    "    # Open the video file\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_in_filepath)\n",
    "\n",
    "    nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    fps = video_reader.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    video_writer = cv2.VideoWriter(video_out_filepath,\n",
    "                            cv2.VideoWriter_fourcc(*'mp4v'),\n",
    "                            fps,\n",
    "                            (frame_w, frame_h))\n",
    "\n",
    "    # Loop through the video frames\n",
    "    for i in tqdm(range(nb_frames)):\n",
    "        # Read a frame from the video\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLO inference on the frame on GPU Device 0\n",
    "            results = model(frame, device=0)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Write the annotated frame\n",
    "            video_writer.write(annotated_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    video_writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad2ae2-5136-470d-b7c3-1b669304a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "video_in_file = \"pen_highlighter.mp4\"\n",
    "basename = Path(video_in_file).stem\n",
    "video_out_file = os.path.join(basename + '_detected' + '.mp4')\n",
    "model = YOLO(\"best_int8_openvino_model\", task=\"detect\")\n",
    "write_video(video_in_file, video_out_file, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
